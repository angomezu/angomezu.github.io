<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Angel A. Barrera Gomez</title>
  <link rel="stylesheet" href="assets/style.css" />
</head>
<body>
  <div class="wrap">
    <aside class="side">
      <img class="photo" src="assets/prof_pic.png" alt="Angel portrait" />
      <h1>Angel A. Barrera Gomez</h1>
      <p class="role">B.E. Computer Systems Engineering • M.S. Data Science • 3D Perception • Embodied AI</p>

      <div class="contact">
        <a href="mailto:angomezu@gmail.com">angomezu@gmail.com</a>
        <div class="muted">Johnson City, TN, USA</div>
      </div>

      <nav class="nav">
        <a href="assets/Angel_Barrera_Resume.pdf">
          <span style="display:inline-flex; align-items:center; gap:6px;">
            <!-- Document icon -->
            <svg width="16" height="16" viewBox="0 0 24 24" fill="none"
                 xmlns="http://www.w3.org/2000/svg">
              <path d="M6 2h9l5 5v15a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2z"
                    stroke="currentColor" stroke-width="2"/>
              <path d="M14 2v6h6" stroke="currentColor" stroke-width="2"/>
            </svg>
            Curriculum Vitae
          </span>
        </a>
        <a href="https://github.com/angomezu" target="_blank">
          <svg width="16" height="16" viewBox="0 0 24 24" style="vertical-align:middle;margin-right:6px;">
            <path fill="currentColor"
              d="M12 .5C5.7.5.5 5.7.5 12c0 5.1 3.3 9.4 7.9 10.9.6.1.8-.3.8-.6v-2.1c-3.2.7-3.9-1.4-3.9-1.4-.5-1.2-1.2-1.6-1.2-1.6-1-.7.1-.7.1-.7 1.1.1 1.7 1.1 1.7 1.1 1 .1.8 2.2 3.3 1.6.1-.8.4-1.3.7-1.6-2.6-.3-5.3-1.3-5.3-5.8 0-1.3.5-2.3 1.2-3.1-.1-.3-.5-1.5.1-3.1 0 0 1-.3 3.2 1.2a11 11 0 0 1 5.8 0c2.2-1.5 3.2-1.2 3.2-1.2.6 1.6.2 2.8.1 3.1.8.8 1.2 1.8 1.2 3.1 0 4.5-2.7 5.5-5.3 5.8.4.3.8 1 .8 2.1v3.1c0 .3.2.7.8.6A11.5 11.5 0 0 0 23.5 12C23.5 5.7 18.3.5 12 .5z"/>
          </svg>
          GitHub
        </a>
        <a href="https://www.linkedin.com/in/angomezu/" target="_blank">
          <svg width="16" height="16" viewBox="0 0 24 24" style="vertical-align:middle;margin-right:6px;">
            <path fill="currentColor"
              d="M4.98 3.5a2.5 2.5 0 1 0 0 5a2.5 2.5 0 0 0 0-5zM3 8.98h3.96V21H3zM9.5 8.98H13v1.64h.05c.49-.93 1.69-1.91 3.48-1.91C20.1 8.71 21 11 21 14.1V21h-3.96v-6.1c0-1.45-.03-3.31-2.02-3.31-2.02 0-2.33 1.58-2.33 3.21V21H9.5z"/>
          </svg>
          LinkedIn
        </a>
      </nav>
    </aside>

    <main class="main">
      <section id="about">
        <h2>About</h2>
        <p>
          I’m a data scientist and engineer with a research focus on geometric representation learning for perception under
          real-world constraints. My core technical foundation is 3D perception and geometry-aware deep learning, working with
          real sensor data such as LiDAR point clouds and structured logs, where noise, ambiguity, and limited supervision are
          the norm rather than the exception.
        </p>
        <p>
          My current interests center on how meaningful geometric and compositional structure in learned representations affects
          robustness, generalization, and uncertainty. Through applied research, I’ve seen that when representations fail to
          preserve underlying structure, models become brittle or overconfident on novel configurations—making reliability a
          representation problem, not just a modeling one.
        </p>
        <p>
          I’m particularly interested in building perception systems that can serve as reliable foundations for embodied and
          interactive intelligence, especially in settings involving partial observability, domain shift, and human oversight.
          While I have not yet worked directly on policy learning for embodied agents, my work is intentionally focused on the
          perception, structure, and evaluation layer needed to support data-efficient learning and safe downstream
          decision-making.
        </p>
      </section>
    </main>

      <!--<section id="research">
        <h2>Research</h2>
      
        <p><strong>PhD identity:</strong> Researcher in compositional visual perception and data-efficient learning</p>
      
        <p>
          Building on my experience with geometry-aware deep learning on real 3D sensor data, my research interests focus on how
          visual representations can be learned as structured compositions of reusable attributes and relations, rather than as
          monolithic patterns. I am particularly interested in compositional learning for computer vision as a foundation for
          robust, data-efficient perception in real-world systems.
        </p>
      
        <p>
          My work is motivated by settings where data are limited, observations are noisy or incomplete, and generalization
          beyond seen configurations is essential. In these contexts, learning explicit structure—such as geometric primitives,
          spatial relations, and part–whole hierarchies—provides a principled way to improve robustness, interpretability, and
          transfer.
        </p>
      
        <h3>Current research themes include:</h3>
        <ul>
          <li>
            <strong>Compositional perception:</strong> learning object representations as combinations of attributes, parts, and
            relations; geometric structure in 3D point clouds; compositional generalization under distribution shift.
          </li>
          <li>
            <strong>Data-efficient learning:</strong> representation learning under limited supervision; leveraging inductive
            biases and structured priors to reduce dependence on large labeled datasets.
          </li>
          <li>
            <strong>Robust real-world perception:</strong> handling occlusion, noise, and class imbalance in 3D sensing;
            diagnosing and mitigating shortcut learning in vision models.
          </li>
          <li>
            <strong>Embodied perception (application context):</strong> using compositional visual representations to support
            downstream decision-making in embodied and interactive systems.
          </li>
        </ul>
      
        <h3>Bridge from applied research:</h3>
        <p>
          My work at Oak Ridge National Laboratory directly informs this agenda. There, I developed geometry-aware deep learning
          models for 3D LiDAR point-cloud semantic segmentation under real-world constraints, including sensor noise, partial
          observability, and severe class imbalance. This experience highlighted both the strengths and limitations of end-to-end
          learning, and motivated my focus on structured, attribute-based representations and rigorous evaluation pipelines that
          matter beyond benchmark performance.
        </p>
      </section>-->

      <section id="projects">
        <h2>Selected Projects</h2>
        
        <div class="card">
          <h3>3D LiDAR Plant Organ Segmentation</h3>
          
          <div class="img-grid">
            <a href="assets/prediction.gif" target="_blank">
              <img src="assets/prediction.gif" alt="Segmentation result">
            </a>
          
            <a href="assets/LiDAR_Scan.jpg" target="_blank">
              <img src="assets/LiDAR_Scan.jpg" alt="3D LiDAR scan">
            </a>
          
            <a href="assets/APPL_Facility.png" target="_blank">
              <img src="assets/APPL_Facility.png" alt="Scanning facility">
            </a>
          </div>
            
            <p class="muted">Point cloud segmentation • geometric deep learning • robust evaluation</p>
            <ul>
              <li>Developed a geometry-aware deep learning pipeline for plant organ segmentation from 3D LiDAR point clouds.</li>
              <li>Engineered local geometric descriptors and evaluated under class imbalance and partial observability (occlusion).</li>
              <li>Current best configuration reports ~65.6% mIoU and ~82% stem recall.</li>
            </ul>
            <p><a href="https://github.com/angomezu/geometric-deep-learning-plant-organ-segmentation.git">Project page →</a></p>
          </div>
        
        <div class="card">
          <h3>EEG Motor Imagery Classification (Conv1D CNN)</h3>
          
          <div class="img-grid">
            <a href="assets/64_channel_sharbrough.png" target="_blank">
              <img
                src="assets/64_channel_sharbrough.png"
                alt="64-channel EEG electrode layout (Sharbrough system)"
              />
            </a>
          
            <a href="assets/class_distribution_pre_smote.png" target="_blank">
              <img
                src="assets/class_distribution_pre_smote.png"
                alt="Class distribution of motor imagery EEG dataset"
              />
            </a>
          
            <a href="assets/EGG_Signal_After-Mergin.png" target="_blank">
              <img
                src="assets/EGG_Signal_After-Mergin.png"
                alt="Sample EEG signal after preprocessing and merging"
              />
            </a>
        </div>
          
          <p class="muted">Signal processing • deep learning • generalization challenges</p>
          <ul>
            <li>Built a full pipeline to classify left vs. right fist motor imagery from PhysioNet EEG (20 subjects, 64 channels, 160 Hz).</li>
            <li>Compared CSP-based baselines vs deep models; final 2-layer Conv1D CNN reached 76.61% accuracy (ROC-AUC 0.79).</li>
            <li>Analyzed subject-wise generalization (avg. accuracy 51.8%) and documented future work for domain adaptation and transfer learning.</li>
          </ul>
          <p><a href="https://github.com/angomezu/bci-motor-classification-cnn">Repository →</a></p>
        </div>

        <div class="card">
          <h3>CRM → PostgreSQL ETL for Real Estate Analytics (Render + Power BI)</h3>
        
          <div class="img-grid">
            <a href="assets/manager_example.png" target="_blank">
              <img
                src="assets/manager_example.png"
                alt="Power BI executive performance dashboard"
              />
            </a>
        
            <a href="assets/seller_example.png" target="_blank">
              <img
                src="assets/seller_example.png"
                alt="Power BI advisor-level sales dashboard"
              />
            </a>
        
            <a href="assets/presentation.jpg" target="_blank">
              <img
                src="assets/presentation.jpg"
                alt="Client presentation of Power BI analytics system"
              />
            </a>
          </div>
        
          <a href="assets/fiinbro_architecture.svg" target="_blank">
            <img
              src="assets/fiinbro_architecture.svg"
              alt="FIINBRO cloud ETL and BI system architecture"
              style="width:100%; border-radius:12px; margin-top:12px;"
            />
          </a>
        
          <p class="muted">Data engineering • event-driven ingestion • BI system design</p>
        
          <ul>
            <li>Built a cloud BI system that streams CRM events via Flask webhooks into PostgreSQL on Render.</li>
            <li>Combined real-time ingestion with scheduled incremental API sync, preserving full event history for auditability.</li>
            <li>Delivered 8 interactive Power BI dashboards using a standardized DAX measure library (60+ measures).</li>
          </ul>
        
          <p>
            <a href="https://github.com/angomezu/CRM-to-PostgreSQL-ETL-for-Real-Estate-Analytics">
              Repository →
            </a>
          </p>
        </div>

        <div class="card">
          <h3>Predicting Hospital Readmission (Logistic Regression in R)</h3>
          <p class="muted">Statistical modeling • interpretability • healthcare analytics</p>
          <ul>
            <li>Modeled hospital readmission risk on 25,000 patient records using logistic regression with stepwise AIC selection.</li>
            <li>Achieved ~61.7% test accuracy (AUC 0.662) and identified key drivers (length of stay, prior visits, medication/labs, age).</li>
          </ul>
          <p><a href="https://github.com/angomezu/Predicting-Hospital-Readmission">Repository →</a></p>
        </div>

        <div class="card">
          <h3>Apex Capital: Financial + ESG Decision Support System (Power BI + Python + MySQL)</h3>
        
          <div class="img-grid">
            <a href="assets/page_1.png" target="_blank">
              <img
                src="assets/page_1.png"
                alt="Apex Capital ESG risk-adjusted opportunity map dashboard"
              />
            </a>
        
            <a href="assets/page_2.png" target="_blank">
              <img
                src="assets/page_2.png"
                alt="Apex Capital portfolio and risk benchmarking dashboard"
              />
            </a>
        
            <a href="assets/database_mysql.png" target="_blank">
              <img
                src="assets/database_mysql.png"
                alt="MySQL database schema and investment universe table"
              />
            </a>
          </div>
        
          <p class="muted">ETL + data integrity • decision support • analytics engineering</p>
        
          <ul>
            <li>Built a full-stack prototype DSS for “dual-mandate” investing (value + ESG), merging multi-source financial and ESG datasets.</li>
            <li>Implemented an ETL workflow with data quality discovery (e.g., mismatched tickers, missing ESG coverage) and schema-enforced loading into MySQL.</li>
            <li>Delivered a Power BI “financial terminal” dashboard with context-aware DAX measures (sector benchmarking, investable gating, ESG null handling).</li>
          </ul>
        
          <p>
            <a href="https://github.com/angomezu/Financial-Analytics-DSS">Repository →</a>
          </p>
        </div>

        <div class="card">
          <h3>PDF Charge Parser (Python GUI)</h3>
          <p class="muted">Automation tool • PDF parsing • Excel reporting</p>
          <ul>
            <li>Built a lightweight desktop tool to parse telecom billing PDFs and extract roaming/long-distance charges into a clean Excel report.</li>
            <li>Implemented robust parsing with PyMuPDF and rule-based extraction, wrapped in a simple Tkinter GUI with progress tracking.</li>
          </ul>
          <p><a href="https://github.com/angomezu/pdf_charge_parser">Repository →</a></p>
        </div>
      </section>

      <section id="goals">
        <h2>Goals</h2>
        <ul>
          <li><strong>Research direction:</strong> grow from geometry-aware 3D perception into embodied AI (perception → learning → action), with an emphasis on robustness and data efficiency.</li>
          <li><strong>Near-term:</strong> turn the ORNL 3D LiDAR project into a formal research write-up and submission.</li>
          <li><strong>Skill ramp:</strong> deepen PyTorch and modern CV tooling toward robotics-relevant perception (3D, multimodal fusion, self-supervised learning).</li>
          <li><strong>Career:</strong> pursue roles and/or a PhD path aligned with perception for robotics and real-world intelligent systems.</li>
        </ul>
      </section>

      <section id="references">
        <h2>References</h2>
      
        <ul class="references">
      
          <li>
            <strong>Ghaith Husari, Ph.D.</strong><br>
            Associate Professor, Data Analytics & Cybersecurity<br>
            East Tennessee State University<br>
            <span class="muted">Instructor — CSCI 5047 Data Analytics & Visualization</span><br>
            <a href="mailto:husari@etsu.edu">husari@etsu.edu</a>
          </li>

          <li>
            <strong>Joseph Antone</strong><br>
            Senior Project Manager (Retired)<br>
            The AES Corporation<br>
            <span class="muted">Former Project Manager</span><br>
            <a href="mailto:josephantone38@gmail.com">josephantone38@gmail.com</a>
          </li>

          <li>
            <strong>Caleb Bennett</strong><br>
            Director, International Enrollment & Services<br>
            East Tennessee State University<br>
            <span class="muted">Direct Supervisor — Graduate Assistantship</span><br>
            <a href="mailto:bennettcb@etsu.edu">bennettcb@etsu.edu</a>
          </li>
      
          <li>
            <strong>Iliana Berganza</strong><br>
            Customer Service Team Leader<br>
            The AES Corporation<br>
            <span class="muted">Former Co-Worker</span><br>
            <a href="mailto:Iliana.berganza@aes.com">Iliana.berganza@aes.com</a>
          </li>
      
        </ul>
      </section>
      
      <section id="updates">
        <h2>Updates</h2>
        <ul class="updates">
          <li><span class="date">2026</span> Searching for a PhD to make a transition toward embodied AI: robust 3D perception → learning for manipulation/HRI.</li>
          <li><span class="date">2026-01</span> Preparing 3D LiDAR Plant Organ Segmentation project write-up for submission.</li>
          <li><span class="date">2025-12</span> Completed M.S. in Applied Data Science at East Tennessee State University (GPA: 3.79).</li>
          <li><span class="date">2025-12</span> Successfully defended research internship presentation at Oak Ridge National Laboratory.</li>
        </ul>
      </section>

      <footer class="footer">
        © <span id="y"></span> Angel A. Barrera Gomez
      </footer>
    </main>
  </div>

  <script>document.getElementById("y").textContent = new Date().getFullYear();</script>
</body>
</html>
